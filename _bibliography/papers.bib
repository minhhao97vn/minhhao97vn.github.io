---
---

@article{van2025survey,
  abbr={arXiv},
  title={A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools},
  author={Van, Minh-Hao and Verma, Prateek and Zhao, Chen and Wu, Xintao},
  journal={arXiv preprint arXiv:2506.20743},
  year={2025},
  selected=true
}

@article{van2025influence,
  abbr={JDSA},
  title={Influence-based approaches for tumor classification in noisy brain MRI with deep learning and vision-language models},
  author={Van, Minh-Hao and Carey, Alycia N and Wu, Xintao},
  journal={International Journal of Data Science and Analytics},
  pages={1--13},
  year={2025},
  publisher={Springer},
  selected=true
}

@inproceedings{bhaila-etal-2025-soft,
    abbr={NAACL'25},
    title = "Soft Prompting for Unlearning in Large Language Models",
    author = "Bhaila, Karuna  and
      Van, Minh-Hao  and
      Wu, Xintao",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.204/",
    doi = "10.18653/v1/2025.naacl-long.204",
    pages = "4046--4056",
    ISBN = "979-8-89176-189-6",
    abstract = "The widespread popularity of Large Language Models (LLMs), partly due to their emerging in-context learning ability, has highlighted the importance of ethical and safety considerations for deployment. Motivated by corresponding data protection guidelines, we investigate machine unlearning for LLMs. In contrast to the growing literature on fine-tuning methods to achieve unlearning, we focus on a comparatively lightweight alternative called soft prompting to realize unlearning in LLMs. With losses designed to enforce forgetting as well as utility preservation, our framework Soft Prompting for Unlearning (SPUL) learns prompt tokens that are prepended to a query to induce unlearning of specific training examples at inference time without updating LLM parameters. We conduct a rigorous evaluation of the proposed method, and results indicate that SPUL can significantly improve the trade-off between utility and forgetting for text classification and question-answering. We further validate our method with LLMs of varying parameter sizes to highlight its flexibility and provide detailed insights into the choice of hyperparameters and the influence of the size of unlearning data."
    selected=true
}

@article{bhaila2024fair,
  abbr={arXiv},
  title={Fair In-Context Learning via Latent Concept Variables},
  author={Bhaila, Karuna and Van, Minh-Hao and Edemacu, Kennedy and Zhao, Chen and Chen, Feng and Wu, Xintao},
  journal={arXiv preprint arXiv:2411.02671},
  year={2024},
  selected=true
}

@inproceedings{carey2024evaluating,
  abbr={IJCNN'24},
  title={Evaluating the impact of local differential privacy on utility loss via influence functions},
  author={Carey, Alycia N and Van, Minh-Hao and Wu, Xintao},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--10},
  year={2024},
  organization={IEEE},
  selected=true
}

@article{van2024large,
  abbr={CHASE'24},
  title={On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study},
  author={Van, Minh-Hao and Verma, Prateek and Wu, Xintao},
  journal={arXiv preprint arXiv:2402.14162},
  year={2024}
}

@article{vinay2024context,
  abbr={arXiv},
  title={In-Context Learning Demonstration Selection via Influence Analysis},
  author={Vinay M, S and Van, Minh-Hao and Wu, Xintao},
  journal={arXiv e-prints},
  pages={arXiv--2402},
  year={2024}
}

@inproceedings{van2024robust,
  abbr={PAKDD'24},
  title={Robust Influence-Based Training Methods for Noisy Brain MRI},
  author={Van, Minh-Hao and Carey, Alycia N and Wu, Xintao},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  pages={246--257},
  year={2024},
  organization={Springer},
  selected=true
}

@article{van2023detecting,
  abbr={Defactify@AAAI'24},
  title={Detecting and correcting hate speech in multimodal memes with large visual language model},
  author={Van, Minh-Hao and Wu, Xintao},
  journal={arXiv preprint arXiv:2311.06737},
  year={2023},
  selected=true
}

@inproceedings{van2023hint,
  abbr={ICDM'23},
  title={HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks},
  author={Van, Minh-Hao and Carey, Alycia N and Wu, Xintao},
  booktitle={2023 IEEE International Conference on Data Mining (ICDM)},
  pages={608--617},
  year={2023},
  organization={IEEE},
  selected=true
}

@inproceedings{van2022defending,
  abbr={BigData'22},
  title={Defending evasion attacks via adversarially adaptive training},
  author={Van, Minh-Hao and Du, Wei and Wu, Xintao and Chen, Feng and Lu, Aidong},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)},
  pages={1515--1524},
  year={2022},
  organization={IEEE},
  selected=true
}

@inproceedings{van2022poisoning,
  abbr={DASFAA'22},
  title={Poisoning attacks on fair machine learning},
  author={Van, Minh-Hao and Du, Wei and Wu, Xintao and Lu, Aidong},
  booktitle={International Conference on Database Systems for Advanced Applications},
  pages={370--386},
  year={2022},
  organization={Springer International Publishing Cham},
  selected=true
}

@inproceedings{hao2019predicting,
  abbr={ACOMP'19},
  title={Predicting Cryptocurrency Price Movements Based on Social Media},
  author={Hao, Van Minh and Huy, Nguyen Huynh and Dao, Bo and Mai, Thanh-Tan and Nguyen-An, Khuong},
  booktitle={2019 International Conference on Advanced Computing and Applications (ACOMP)},
  pages={57--64},
  year={2019},
  organization={IEEE},
  selected=true
}